{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flask.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPifxcAoSL5o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daa2ff86-649f-43e4-c868-2edbd9aeef1a"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "!pip install pyngrok\n",
        "!sudo pip install mtcnn\n",
        "!wget 'https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-windows-amd64.zip'\n",
        "!unzip ngrok-stable-windows-amd64.zip\n",
        "!ngrok authtoken 1ptGlHPRRq0SOuf93xUijgxjHoh_3oVnNMTu52qvyLw9aL2vs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2020.12.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.7/dist-packages (5.0.4)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (3.13)\n",
            "Requirement already satisfied: mtcnn in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (4.1.2.30)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.0.0->mtcnn) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras>=2.0.0->mtcnn) (1.15.0)\n",
            "--2021-03-18 08:07:20--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-windows-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 34.196.37.54, 54.145.36.98, 3.223.239.191, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|34.196.37.54|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13819230 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-windows-amd64.zip.1’\n",
            "\n",
            "ngrok-stable-window 100%[===================>]  13.18M  18.6MB/s    in 0.7s    \n",
            "\n",
            "2021-03-18 08:07:21 (18.6 MB/s) - ‘ngrok-stable-windows-amd64.zip.1’ saved [13819230/13819230]\n",
            "\n",
            "Archive:  ngrok-stable-windows-amd64.zip\n",
            "replace ngrok.exe? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok.exe               \n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYKrFF1R5i9w"
      },
      "source": [
        "from os import listdir\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from matplotlib import pyplot\n",
        "# from mtcnn.mtcnn import MTCNN\n",
        "from numpy import load\n",
        "from sklearn.metrics import accuracy_score\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.svm import SVC\n",
        "from os import listdir\n",
        "from os.path import isdir\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot\n",
        "from numpy import savez_compressed\n",
        "from numpy import asarray\n",
        "from mtcnn.mtcnn import MTCNN\n",
        "from numpy import load\n",
        "from numpy import expand_dims\n",
        "from numpy import asarray\n",
        "from numpy import savez_compressed\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "# from trainingfile import get_embedding\n",
        "from funcutils import *\n",
        "# from trainingfile import get_embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TN20SGqx5al"
      },
      "source": [
        "#Run This cell to train the network\n",
        "# !python trainingfile.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "lg2nlkudSOU5",
        "outputId": "ff3ef78d-7cce-4d4c-b6d7-c41e6479200b"
      },
      "source": [
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://a11fgdip0m6-496ff2e9c6d22116-5000-colab.googleusercontent.com/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aqbv8dBr2Vat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f73dab-568b-4bcd-a5ce-7423fbfb7f68"
      },
      "source": [
        "from PIL import Image\n",
        "import pickle\n",
        "def extract_face(filename, required_size=(160, 160)):\n",
        "\t# load image from file\n",
        "\timage = Image.open(filename)\n",
        "\t# convert to RGB, if needed\n",
        "\timage = image.convert('RGB')\n",
        "\t# convert to array\n",
        "\tpixels = asarray(image)\n",
        "\t# create the detector, using default weights\n",
        "\tdetector = MTCNN()\n",
        "\t# detect faces in the image\n",
        "\tresults = detector.detect_faces(pixels)\n",
        "\t# extract the bounding box from the first face\n",
        "\tx1, y1, width, height = results[0]['box']\n",
        "\t# bug fix\n",
        "\tx1, y1 = abs(x1), abs(y1)\n",
        "\tx2, y2 = x1 + width, y1 + height\n",
        "\t# extract the face\n",
        "\tface = pixels[y1:y2, x1:x2]\n",
        "\t# resize pixels to the model size\n",
        "\timage = Image.fromarray(face)\n",
        "\timage = image.resize(required_size)\n",
        "\tface_array = asarray(image)\n",
        "\treturn face_array\n",
        "#NOW TESTING FOR AN IMAGE\n",
        "new_facenet_model_for_getting_embedding = load_model('/content/drive/MyDrive/MiniProject/facenet_keras.h5')\n",
        "def predict_image(filepath):\n",
        "  f=open('/content/drive/MyDrive/MiniProject/picklefile.txt','rb')\n",
        "  d=pickle.loads(f.read())\n",
        "  model=d['model']\n",
        "  out_encoder=d['outencoder']\n",
        "  X=list()\n",
        "  faces=list()\n",
        "  testembed=list()\n",
        "  face=extract_face(filepath)\n",
        "  #face.shape\n",
        "  faces.append(face)\n",
        "  X.extend(faces)\n",
        "  Predic=asarray(X)\n",
        "  # load the facenet model\n",
        "  print('Loaded Model')\n",
        "  #Predic.shape\n",
        "  for face_pixels in Predic:\n",
        "    embedding = get_embedding(new_facenet_model_for_getting_embedding , face_pixels)\n",
        "    testembed.append(embedding)\n",
        "  testembed = asarray(testembed)\n",
        "  print(testembed.shape)\n",
        "  # prediction for the face\n",
        "  #samples = expand_dims(testembed, axis=0)\n",
        "  #print(samples.shape)\n",
        "  yhat_class = model.predict(testembed)\n",
        "  yhat_prob = model.predict_proba(testembed)\n",
        "  # get name\n",
        "  class_index = yhat_class[0]\n",
        "  class_probability = yhat_prob[0,class_index] * 100\n",
        "  print(yhat_prob,int(yhat_prob[0,class_index]))\n",
        "  return out_encoder.inverse_transform(yhat_class)[0]\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWel8UaiSRci",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd9c96d-ad93-4e90-ceae-f86f81fa90ef"
      },
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask,flash,request,redirect,url_for,render_template\n",
        "from werkzeug.utils import secure_filename\n",
        "import os\n",
        "import os\n",
        "import socket\n",
        "import time\n",
        "from pyngrok import ngrok\n",
        "\n",
        "host = '1.tcp.ngrok.io'\n",
        "port = 12340\n",
        "\n",
        "# Create a TCP socket\n",
        "sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "\n",
        "# Bind a local socket to the port\n",
        "server_address = (\"\", port)\n",
        "sock.bind(server_address)\n",
        "sock.listen(1)\n",
        "\n",
        "# Open a ngrok tunnel to the socket\n",
        "\n",
        "app = Flask(__name__,template_folder='/content')\n",
        "# run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "public_url = ngrok.connect(port, \"tcp\", options={\"remote_addr\": \"{}:{}\".format(host, port)})\n",
        "print(\"ngrok tunnel \\\"{}\\\" -> \\\"tcp://127.0.0.1:{}/\\\"\".format(public_url, port))\n",
        "\n",
        "@app.route(\"/\",methods=['GET','POST'])\n",
        "def uploadfile():\n",
        "  if request.method=='POST':\n",
        "    file=request.files['image']\n",
        "    if file:\n",
        "      filename=secure_filename(file.filename)\n",
        "      file.save(filename)\n",
        "      print('image saved')\n",
        "      person_name=predict_image(filepath=f'/content/{filename}')\n",
        "      while True:\n",
        "          connection = None\n",
        "          try:\n",
        "              # Wait for a connection\n",
        "              print(\"\\nWaiting for a connection ...\")\n",
        "              connection, client_address = sock.accept()\n",
        "\n",
        "              print(\"... connection established from {}\".format(client_address))\n",
        "              # name=predict_image(filepath=path)\n",
        "              # Receive the message, send a response\n",
        "              while True:\n",
        "                  data = connection.recv(1024)\n",
        "                  if data:\n",
        "                      print(\"Received: {}\".format(data.decode(\"utf-8\")))\n",
        "\n",
        "                      message = person_name\n",
        "                      print(\"Sending: {}\".format(message))\n",
        "                      connection.sendall(message.encode(\"utf-8\"))\n",
        "                      sock.close()\n",
        "                      return person_name\n",
        "                  else:\n",
        "                      break\n",
        "          except KeyboardInterrupt:\n",
        "              print(\" Shutting down server.\")\n",
        "\n",
        "              if connection:\n",
        "                  connection.close()\n",
        "              break\n",
        "      sock.close()\n",
        "      return person_name\n",
        "      # return \"got your image\"\n",
        "  else:\n",
        "    return render_template('sample.html')\n",
        "@app.route('/home')\n",
        "def index():\n",
        "  return \"<h1>this is not home page</h1>\"\n",
        "app.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ngrok tunnel \"NgrokTunnel: \"tcp://0.tcp.ngrok.io:11000\" -> \"localhost:12340\"\" -> \"tcp://127.0.0.1:12340/\"\n",
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            "127.0.0.1 - - [18/Mar/2021 08:16:12] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/Mar/2021 08:16:12] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "image saved\n",
            "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2d9fc018c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2d9fc018c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2da65c25f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2da00fd710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Loaded Model\n",
            "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2d9fc5ef80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "(1, 128)\n",
            "[[9.99999783e-01 3.82940925e-08 1.01882904e-07 2.51464822e-08\n",
            "  5.20559453e-08]] 0\n",
            "\n",
            "Waiting for a connection ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [18/Mar/2021 08:16:32] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "... connection established from ('127.0.0.1', 56698)\n",
            "Received: pls send data\n",
            "Sending: ben_afflek\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "t=2021-03-18T08:16:32+0000 lvl=warn msg=\"failed to open private leg\" id=e54ea33d39e3 typ=proxy privaddr=localhost:12340 err=\"dial tcp 127.0.0.1:12340: connect: connection refused\"\n",
            "127.0.0.1 - - [18/Mar/2021 08:16:32] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "127.0.0.1 - - [18/Mar/2021 08:16:52] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "127.0.0.1 - - [18/Mar/2021 08:16:52] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpxS23JBTwVK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}